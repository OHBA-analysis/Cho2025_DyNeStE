# Nottingham MEGUK

### üîé Overview

This directory contains scripts for model training and data analysis on the Nottingham MEGUK dataset.
They are organised into three categories:

1. Data Processing & Inspection
   * For examining and organising the dataset
2. Model Training
   * For training DyNeStE and TDE-HMM models
3. Data Analysis
   * For analysing and visualising trained models

For detailed descriptions of each script, please refer to the sections below.

## üïµüèº Data Processing & Inspection

We have two scripts for inspecting and organising the datasets:

| Scripts               | Description                                                                  | Figures |
| :-------------------- | :--------------------------------------------------------------------------- | :------ |
| `get_demographics.py` | Summarises subject age, sex, and handedness in the Nottingham MEGUK dataset. | A3      |
| `prepare_data.py`     | Prepares and saves the dataset for model training.                           | -       |

**NOTE:** The figures in the Appendix are indicated by the prefix "A".

## ‚öôÔ∏è Model Training

DyNeStE and TDE-HMM models are trained using the prepared dataset.
When multiple models are trained, we select the one that performs best by comparing their losses (i.e., variational free energy).

| Scripts                   | Description                                                               |
| :------------------------ | :------------------------------------------------------------------------ |
| `01_train_dyneste.py`     | Trains a DyNeStE model on the data and saves inferred parameters.         |
| `02_train_hmm.py`         | Trains a TDE-HMM model on the data and saves inferred parameters.         |
| `03_select_best_model.py` | Selects the best model out of multiple model runs based on their losses.  |

**NOTE:** When training a model, you can specify whether to use the full set of subjects or split-half subsets. 
For a use case of how to randomly split a dataset in half, refer to the `prepare_data.py` script in [Data Processing & Inspection](#-data-processing--inspection).

## üßê Data Analysis

For the data analysis, we have six main scripts:

| Scripts                                     | Description                                                                                      | Figures      |
| :------------------------------------------ | :----------------------------------------------------------------------------------------------- | :----------- |
| `04_analyze_network_descriptions.py`        | Computes dynamic resting state networks and their network profiles.                              | 3, A2, A4    |
| `05_analyze_network_dynamics.py`            | Analyses network state dynamics and compares them between DyNeStE and HMM.                       | 4            |
| `06_analyze_split_half_reproducibility.py`  | Examines and quantifies the split-half reproducibility of the inferred networks.                 | 5, A5        |
| `07_analyze_long_term_dependency.py`        | Computes Fano factor and mutual information from the inferred and generated state time courses.  | -            |
| `08_visualize_long_term_dependency.py`      | Visualises the ability to capture long-term dependencies using computed metrics.                 | 6            |
| `09_run_tinda_analysis.py`                  | Performs the TINDA analysis on state time courses inferred and generated by the trained models.  | 7, 8, 9, A6  |

### üôã‚Äç‚ôÇÔ∏è FAQ: What about the `utils` subdirectory?
The `utils` subdirectory contains essential functions required to run the scripts summarised above. Each script in `utils` includes multiple 
functions. These functions are self-explanatory and include detailed annotations, so their descriptions are not repeated here.
